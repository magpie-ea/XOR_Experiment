---
title: 'Xor-Some Preregistered Study: Preprocessing'
author: "Polina Tsvilodub"
date: "10/18/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(brms)
library(tidyboot)
library(tidybayes)
```

## Read Data

First, the data is loaded.
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
d <- read_csv("./../../data/main/results_73_xor-some-Prolific-main_N275_anonym.csv")  

# separate some and xor data!
d_some <- d %>% filter(main_type == "some") 
d_xor  <- d %>% filter(main_type == "xor")
```

## Clean data

Checking if there are any comments indicating technical issues, to be excluded then:
```{r comments}
d %>% distinct(comments) %>% View()
```

Apply language related exclusion criterion:
Check native languages. Participants not indicating English as (one of) their native language(s) are excluded. We also compute some participant demographics.
```{r languages}
d %>% distinct(languages)
cat("Number of participants before excluding non-natives: ", d %>% distinct(submission_id) %>% count() %>% pull() ) 
# exclude non-natives if necessary
d_native <- d %>% 
 # filter(("en" | "En" | "bri") %in% languages)
  filter(grepl("eng", languages, ignore.case = T))

cat(" Number of participants after excluding non-natives: ", d_native %>% distinct(submission_id) %>% count() %>% pull() )

cat(" Mean age: ", d_native %>% pull(age) %>% mean(., na.rm = T) )
d_native  %>% count(gender) %>% mutate(n = n/80)
```

Check the overall completion time. Participants who complete the experiment in less than 8 minutes are excluded.
```{r}
d_native_completed <- d_native %>% mutate(timeSpent = round(timeSpent, 2)) %>%
  filter(timeSpent > 8) 

cat(" Number of participants who completed the expt in > 8 minutes: ", d_native_completed %>% distinct(submission_id) %>% count() %>% pull() )
```

```{r}
d_native_completed %>% summarize(median_time = median(timeSpent),
                                 mean_time = mean(timeSpent))
```
```{r}
# check the distribution of completion times
d_native_completed %>% 
  ggplot(., aes(x=timeSpent)) +
  geom_density()
```

Apply attention check based exclusion criterion:

```{r}
d_native_attention <- d_native_completed %>% 
  filter(condition == "attention_check") %>% mutate(
  passed_attention_trial = case_when(
    (expected == 0) & (response == 0) ~ T,
    (expected == 100) & (response == 100) ~ T,
    (expected == 50) & (response %>% between(45, 55)) ~ T,
    TRUE ~ F
  )
)

d_native_attention_summary <- d_native_attention %>% 
  group_by(submission_id) %>%
  summarize(attention_prop = mean(passed_attention_trial)) %>%
  mutate(
    passed_attention_check = attention_prop > 0.75
  ) %>% 
  filter(passed_attention_check == TRUE)

d_native_attention_failed <- d_native_attention %>% 
  group_by(submission_id) %>%
  summarize(attention_prop = mean(passed_attention_trial)) %>%
  mutate(
    passed_attention_check = attention_prop > 0.75
  ) %>% 
  filter(passed_attention_check == FALSE)

d_native_attended <- anti_join(d_native_completed, 
                               d_native_attention_failed, 
                               by = c("submission_id"))

cat(" Number of participants failing attention checks: ", d_native_attention_failed %>% distinct(submission_id) %>% count() %>% pull() )

#d_attention_fail_IDs <- right_join(d_raw, d_native_attention_failed, by = c("submission_id")) %>% select(submission_id, prolific_id) %>% distinct()
#d_attention_fail_IDs %>% write_csv("~/Documents/Research/XOR/raw_data/xor-some_prereg_failed_attention_prolificIDs_final.csv")
```

Data frames preparation:

```{r}
d_main <- d_native_attended %>% select(-age, -comments, -education, -endTime, 
                              -gender, -languages, -optionLeft, -optionRight, -startDate,
                              -startTime, -timeSpent, -expected) %>%
  filter(trial_name != "example", trial_name != "attention_check")
d_exmpl <- d_native_attended %>% select(-age, -comments, -education, -endTime, 
                              -gender, -languages, -optionLeft, -optionRight, -startDate,
                              -startTime, -timeSpent, -expected) %>%
  filter(trial_name == "example")
d_critical <- d_main %>% filter(condition == "critical")

d_test <- d_main %>% rowwise() %>% filter(condition == "test") %>% 
  mutate(test_condition = substr(test_question, 6, 9),
         test_condition = ifelse(test_condition == "fals", "false", 
                                 ifelse(test_condition == "unce", "uncertain",
                                        test_condition)))
```

Investigate if the comprehension questions received expected responses on by-question basis:
```{r}
d_test %>% group_by(ID, test_question) %>% 
  mutate(
    expected = case_when( test_condition == "true" ~ 100,
                          test_condition == "false" ~ 0,
                          TRUE ~ 50)
  ) %>%
  summarise(
    expected = mean(expected),
    response = mean(response),
    difference = abs(expected - response)
  ) %>% 
  arrange(., desc(difference))

# look at the vignette text and the qeustion of the worst performing item
d_test %>% filter(ID == 64, test_question == "test_false1") %>% select(prompt, QUD) %>% View()
```

Exclude participants based on example trials, comprehension question performance, and response patterns.
Participants who gave all responses within the range of 10 and participants who failed more than 0.2 of the comprehension questions are excluded from analysis. 
Participants who failed all example trials are excluded, as well. 

```{r exclusions}
# get participants failing example trials
d_exmpl_fail <- d_exmpl %>% group_by(submission_id) %>% 
  mutate(example_condition = ifelse(grepl("as certainly true", question), "true", 
                                    ifelse(grepl("as certainly false", question), "false",
                                           "uncertain")),
         passed_example_trial = case_when(example_condition == "true" ~ response >= 80,
                                    example_condition == "false" ~ response <= 20,
                                    example_condition == "uncertain" ~ response >= 30),
       #  check if all trials passed
         passed_example = case_when(sum(passed_example_trial) == 0 ~ FALSE,
                                    TRUE ~ TRUE)
         ) %>% filter(passed_example == F)

cat("Subjects failing the example trials: ", d_exmpl_fail %>% distinct(submission_id) %>% pull() %>% length())

# apply exclusion criteria to main trials
# check range of responses per participant
d_main_fail <- d_main %>% group_by(submission_id) %>%
  mutate(passed_main = case_when(max(response) - min(response) <= 10 ~ FALSE,
                                 TRUE ~ TRUE)
         ) %>% filter(passed_main == F)
cat(" Subjects providing the same ratings throughout the trials: ", d_main_fail %>% distinct(submission_id) %>% pull() %>% length())

# get participants failing comprehension questions
d_test <- d_test %>%
  group_by(submission_id) %>%
  mutate(passed_filler_trial = case_when(test_condition == "true" ~ response >= 60,
                                   test_condition == "false" ~ response <= 40,
                                   test_condition == "uncertain" ~ response %in% (10:90)),
         mean_comprehension = mean(passed_filler_trial),
         passed_filler = mean_comprehension >= 0.8
         ) 

d_test_fail <- d_test %>% 
  filter(passed_filler == F)

cat(" Subjects failing the comprehension trials: ", d_test_fail %>% distinct(submission_id) %>% pull() %>% length())
```

Write out data for plotting:
```{r}
d_test %>% write_csv("./../../data/main/results_prereg_raw_final_test.csv")
```

```{r}
# put it all together
d_full_clean <- anti_join(d_main, d_main_fail, by = "submission_id")
d_full_clean <- anti_join(d_full_clean, d_exmpl_fail, d_test, by = "submission_id")
d_full_clean <- anti_join(d_full_clean, d_test_fail, by = "submission_id")

cat(" Nr. of participants left after cleaning: ", d_full_clean %>% distinct(submission_id) %>% pull() %>% length())
```
Exclude the 201st participant for target N=200:
```{r, results='hide'}
d_full_clean %>% arrange(., desc(submission_id)) %>% distinct() %>% pull(submission_id)

# exclude participant with last submission_id
d_full_clean <- d_full_clean %>% filter(submission_id != 2620)

cat(" Nr. of participants left after cleaning and N=200 extraction: ", d_full_clean %>% distinct(submission_id) %>% pull() %>% length())

```

Write out tidy data:
```{r}
d_full_clean %>% write_csv("./../../data/main/results_prereg_final_tidy.csv")
```

```{r clean}
# get overall mean ratings / subject across comprehension and critical trials 
d_full_clean %>% group_by(submission_id) %>% summarise(mean_rating = mean(response)) %>% arrange(mean_rating)

# get mean ratings / subject in critical trials 
d_full_clean %>% filter(condition == "critical") %>% group_by(submission_id) %>% summarise(mean_rating = mean(response)) %>% arrange(mean_rating)

```

## Transformations

```{r, echo=FALSE}
d_critical_clean <- d_full_clean %>% filter(condition == "critical")
d_critical_long <- d_critical_clean %>% 
  pivot_longer(c(competence, relevance, prior), 
               names_to = "class_condition", 
               values_to = "prior_class")


d_critical_long <- d_critical_long %>% 
  mutate(block = ifelse(block == "comp", "competence", 
                        ifelse(block == "rel", "relevance", ifelse(block == "pri", "prior", block) )))
```

Create more extensive condition labels.

``` {r}
# extending 'conditions' labels to include whether the utterance was present or not
d_critical_long <- d_critical_long %>% 
  mutate(
    block_extended =  ifelse(block %in% c("some", "xor"), "target", block)
  )
```

Z-scoring:
```{r}
d_critical_zScored <- d_critical_long %>% group_by(submission_id, block_extended) %>%
  mutate(block_mean = mean(response),
         block_sd = sd(response),
         response_centered = (response - block_mean)/block_sd,
         # catch the cases where sd is 0 
         response_centered = ifelse(is.na(response_centered), 0, response_centered))

d_critical_zScored_wide <- d_critical_zScored %>% 
  select(submission_id, title, main_type, block_extended, response_centered) %>% 
  unique() %>% 
  pivot_wider(
    names_from = block_extended, 
    values_from = response_centered, 
    values_fn = mean # getting means for double prior measurement in "xor"
  ) 
```

Write out z-scored data
```{r}
d_critical_zScored %>% write_csv("./../../data/main/results_prereg_tidy_final_zScored_long.csv")
d_critical_zScored_wide %>% write_csv("./../../data/main/results_prereg_tidy_final_zScored_wide.csv")
```